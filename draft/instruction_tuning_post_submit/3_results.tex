%%% results.tex %%%
\subsection{Clustering}

Clustering on semantic embeddings and sorting by cluster names over a hierarchy of granularities let us read through the instructions with similar examples being put close together on a list. Figures~\ref{fig:instruction_examples_U2} and \ref{fig:instruction_examples_iwi} show examples.

\begin{figure}
  \centering
  \includegraphics[width=0.95\linewidth]{figures/instruction_examples_U2.png}
  \caption{Examples of instructions clustered by semantic similarity and sorted to put similar items close together. These instructions are all about the band U2, but they have some variety in structure and intent. The last two sentences are in a different E-level cluster; note that these sentences mention Ireland/Irish where the others do not.}
  \label{fig:instruction_examples_U2}
\end{figure}


\begin{figure}
  \centering
  \includegraphics[width=0.95\linewidth]{figures/instruction_examples_identify_which_instrument.png}
  \caption{These sentences are very similar in structure as well as content, and they cluster very tightly together. Examples like these illustrate why we were motivated to focus on longer n-grams, or n-grams of parts of speech, to try to find representations that emphasize syntactic structure.}
  \label{fig:instruction_examples_iwi}
\end{figure}

Examining these clustered examples led us to propose three general dimensions by which instances may be considered similar or different:
\begin{itemize}
\item{\emph{domain}}: The domain dimension is the topic or knowledge domain an instruction applies to (like cars or musical instruments).
\item{\emph{framework}}: The degree to which instructions share syntactic structure (these are things that could be put into a template).
\item{\emph{output format}}: Parts of the instruction specifying how the results should be presented.

\end{itemize}

Examples of regular expressions designed to soft-label cases related to these dimensions are given in Figure~\ref{fig:regex_examples}. These dimensions are by no means exhaustive (for example, another common way to characterize instructions is by the NLP task required to be solved), but we found them useful as a rough framework.

\subsection{Co-occurrence}

Figure~\ref{fig:clusters_xtab_category} was generated by cross-tabulating clusters with categories for two different kinds of clusters (semantic embedding based clusters in panel A, and POS n-gram based clusters n panel B).


\begin{figure}
  \centering
  \includegraphics[width=0.95\linewidth]{figures/clusters_xtab_category.png}
  \caption{Clustermaps of cross-tabulations between clusters and category labels. Panel \textbf{\emph{A}} shows results with clusters generated from \emph{semantic embeddings}, and panel \textbf{\emph{B}} shows clusters generated from \emph{POS n-gram vectors} computed from part-of-speech n-grams. Counts were normalized by dividing by the column sum, so each column shows how the items in a cluster are distributed across categories. Note that though these two ways of clustering instructions use similar naming conventions ('B' indicates the level of granularity, so these clusters are smaller and more focused than 'A' level clusters, but more general than 'C' level), but the clusters in the two panels were computed from completely different representations and the column names (x-axis labels) do not correspond between panels. It is clear from these visualizations that some of the POS n-gram clusters show even stronger relationships to particular categories (eg, classification) than the clusters derived from semantic embeddings.}
  \label{fig:clusters_xtab_category}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=0.90\linewidth]{figures/cooccurrance_2_panels.png}
  \caption{
   \textbf{Co-occurrence graph between category labels, instruction clusters, and response clusters.} \emph{Left Panel:} Wide-angle view. Nodes representing category labels are in red, with those associated with context passages (\texttt{closed\_qa}, \texttt{summarization}, and \texttt{information\_extraction}) using star shapes and the other categories using rectangles. Instruction clusters are shown in light blue, and response clusters are in yellow.
  \emph{Right panel:} A zoomed-in view of the co-occurrence graph showing clusters related to \texttt{classification}, showing clear subcategories characterized by both instruction and response clusters.
  }
  \label{fig:cooccurrance_2_panels}
\end{figure}


The left panel of Figure~\ref{fig:cooccurrance_2_panels} is a high-level view of a co-occurrence graph showing all the common clusters of entries in the instruction and response fields and how they relate to the categories. Because the text is too small to read at this magnification, we have indicated the positions of the nodes representing category labels. Controls are visible in the upper left corner; the button can be used to turn off the physics engine driving force-directed layout, and the slider can be used to select a threshold for filtering out weaker edges. At the edge threshold shown, the nodes for the \emph{summarization} and \emph{creative\_writing} labels each have only one edge connecting them to a cluster node. However, most of the labels form centers of communities, with edges coming in from multiple instruction and response clusters.

The strongest edge on this graph (from 'inst\_B02' to 'open\_qa') has a confidence just over 0.98; that is, more than 98\% of the instructions in that cluster have that category label. The threshold slider is set to 0.26 so the thinnest lines in the figure are just above that strength. There are multiple edges with confidence above 95\% pointing into the \emph{classification} node. Note that the stronger arrows typically go from the less common node to the more common one; since there are only 8 different category labels and every instruction/response pair has a label, the label nodes cover much larger numbers of examples than any of the clusters do.


In the right hand panel of Figure~\ref{fig:cooccurrance_2_panels} we zoom in on the clusters associated with the \textbf{classification} label. The clustering process was performed independently on the \textbf{instruction} (blue nodes) and \textbf{response} fields  (yellow nodes). Labels are shown in red. Note that most of the relationships between instruction and response nodes have edges pointing in both directions, meaning that a high fraction of the instruction/response pairs where the instruction falls into that particular 'inst' cluster also have a response that falls into the indicated 'resp' cluster, and vice versa. A pattern particularly prominent in this view is the association of both elements of instruction/response node pairs with the same category. These indicate clear subcategories. These kinds of patterns are recognizable in other categories, but they are most clear for classification.


\subsection{Examples of patterns found in clusters}

Figure~\ref{fig:regex_examples} shows examples of regular expressions that attempt to capture patterns we noticed when examining clusters.

\begin{figure}
  \centering
  \includegraphics[width=0.95\linewidth]{figures/regex_examples.png}
  \caption{
  Examples of regular expression patterns used for identifying soft labels. Each pattern has a name that is suitable for use as a Pandas column header. The patterns may include positive or negative lookaround assertions so we can specify, for example, that we want it to match 'baseball' but not 'baseball bat' because we noticed cases where baseball bats were used for purposes unrelated to baseball. Each pattern is labeled with a 'dimension' indicating whether it is intended to identify characteristics of syntactic frameworks, specifications of output format, or the topical domain of the instruction.
  }
  \label{fig:regex_examples}
\end{figure}

The 'alternatives' pattern provides an example of how we used the clustering results, examination of examples, and some experimentation with patterns to figure out a signal that helps to explain the clustering.

As we saw in panel B of Figure~\ref{fig:clusters_xtab_category}, several of the POS n-gram clusters are composed almost entirely of classification instructions. To explore this pattern further we used the raw POS n-gram features to predict the classification category with a single decision tree. Most of the signal was found by a simple tree of depth two that only looked at two n-gram patterns; 'punct propn punct propn' and 'punct noun punct noun'. These are either two nouns or two proper nouns followed by punctuation marks. This led us to suspect that the relevant signal is a list of items, so the alternatives pattern looks for markers used to separate items in such a list. Figure~\ref{fig:alternatives_ROC} shows how well simple scores based on this pattern serves to predict the classification category.

\begin{figure}
  \centering
  \floatbox[{\capbeside\thisfloatsetup{capbesideposition={right,top},capbesidewidth=6.0cm}}]{figure}[\FBwidth]
  {  
      \caption{  
       \emph{Using the \texttt{alternatives} pattern in instruction text to predict the \texttt{classification} label.} The regex pattern we have named 'alternatives' recognizes a comma or the word 'or'. If we use a binary flag indicating the presence of this pattern as a predictor for the \texttt{classification} label we get the two-segment ROC curve shown in a the green line. If we instead use the count of the number of times the pattern appears in the text as a predictor, we get the ROC curve shown by the red line. And if we take the ratio of this count to the length of the instruction text, we get even better predictions, as shown by the blue curve.
      }
  }
  {
     \includegraphics[width=0.95\linewidth]{figures/alternatives_ROC.png}
     \label{fig:alternatives_ROC}
  }
\end{figure}

\subsection{Text complexity}

We examined the distribution of readability scores across different sentence embedding clusters within the {\em closed\_qa} instruction category (see Figure~\ref{fig:readability_levels_by_cluster}), observing that clusters within this dataset can differ widely on this metric.

\begin{figure}
  \centering
  \includegraphics[width=0.95\linewidth]{figures/readability_levels_by_cluster.png}
  \caption{
  \emph{Distribution of readability levels across clusters}. Several of these clusters show obvious skew for different readability levels. Cluster 8 focuses on texts detailing geographical facts written in straightforward language, many of which have the lowest readability scores. Cluster 2 primarily covers biographical information about individuals, similarly presented in simple language with many also ranking at the lower readability spectrum. In contrast, Cluster 1 features texts on science and technology, composed in a sophisticated style, and often delves into intricate technical and scientific concepts, resulting in strong skewing toward the highest readability scores.
  }
  \label{fig:readability_levels_by_cluster}
\end{figure}

\subsection{Label distribution across clusters}

Figure~\ref{fig:roc_curves_animals} shows a "cluster ROC curve", which is a new twist on an old type of plot, showing the distribution of a binary label across clusters.

\begin{figure}
  \centering
  \floatbox[{\capbeside\thisfloatsetup{capbesideposition={left,top},capbesidewidth=6.0cm}}]{figure}[\FBwidth]
  {  
      \caption{  
      A "Cluster ROC curve" showing how the frequency of the label for the 'animals' pattern is distributed across clusters at various granularities, Semantic embeddings were used to generate a hierarchical clustering dendrogram, which was sliced at a series of levels to produce numbers of clusters from 2 to 256 on a log2 scale. An ROC curve and associated AUC are computed for each slicing, as indicated by colors. Since each cluster is represented by a distinct segment of the curve, we can see that even in the gray curve (256 clusters) a small number of clusters contain the majority of the cases matching the 'animals' pattern, and a very large fraction of the cases in those clusters match the pattern. 
      }
  }
  {
     \includegraphics[width=0.95\linewidth]{figures/roc_curves_animals.png}
    \label{fig:roc_curves_animals}
  }
\end{figure}
