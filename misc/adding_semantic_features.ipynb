{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract common question forms in Dolly data\n",
    "\n",
    "By parsing the Dolly corpus questions we can identify if it's a question, and what form of question it is. Then this can be used to check its assigned category, and the embedding-based classification of the question type. \n",
    "\n",
    "This notebook defines 3 heuristic rules to identify questions - wh_question(), did_question(), is_question() that use the stop word and root from a sentence to classify sentences.\n",
    "It saves the result in 'misc/dolly-instruction_parse_15k.csv'\n",
    "\n",
    "jma 30 Aug 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load json version \n",
    "import re, os, sys, pprint\n",
    "import spacy as sp          # A production quality linguistic parser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "DATA = '/mnt/512G_hd/repos/dolly_data/databricks-dolly-15k.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['instruction', 'context', 'response', 'category'], dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_data = pd.read_json(DATA, lines=True)\n",
    "d_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the parser for English\n",
    "english_language = sp.load('en_core_web_trf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['be', 'the', 'bread', 'objective', 'or', 'subjective', '?', '.']\n",
      "['VBZ', 'DT', 'NN', 'JJ', 'CC', 'JJ', '.', '.']\n",
      "['AUX', 'DET', 'NOUN', 'ADJ', 'CCONJ', 'ADJ', 'PUNCT', 'PUNCT']\n",
      "['ROOT', 'det', 'nsubj', 'acomp', 'cc', 'conj', 'punct', 'punct']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('do', 'VBP', 'verb, non-3rd person singular present', 'AUX', 'aux', 0),\n",
       " ('the', 'DT', 'determiner', 'DET', 'det', 1),\n",
       " ('place', 'NNS', 'noun, plural', 'NOUN', 'nsubj', 2),\n",
       " ('look', 'VB', 'verb, base form', 'VERB', 'ROOT', 3),\n",
       " ('nice',\n",
       "  'JJ',\n",
       "  'adjective (English), other noun-modifier (Chinese)',\n",
       "  'ADJ',\n",
       "  'acomp',\n",
       "  4),\n",
       " ('?', '.', 'punctuation mark, sentence closer', 'PUNCT', 'punct', 5)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse a sentence.  This give us the raw features to tell if its a question. \n",
    "\n",
    "def run_parse(the_sentence):\n",
    "    phrase = english_language(the_sentence)\n",
    "    # print([(i, i.label_) for i in phrase.ents]) We dont need the entities. \n",
    "    the_parse = []\n",
    "    found_root = False\n",
    "    for k, token in enumerate(phrase):\n",
    "        # 'Stop' words are the closed classes e.g. pronouns, of words.  Only a small finite number of words make up the class.\n",
    "        # Stop words  plus the auxilaries and verb give us all the gramatical structure we need.\n",
    "        if token.dep_ in ('ROOT', 'aux'):\n",
    "            the_parse.append((token.lemma_, token.tag_, sp.explain(token.tag_), token.pos_, token.dep_, k))\n",
    "            # One word after after the main verb is needed for inversions.  \n",
    "            found_root = True\n",
    "        elif token.is_stop or found_root:\n",
    "            # print(token.text, token.lemma_, end = '\\t')\n",
    "            # print(token.is_stop, token.tag_, token.pos_, token.dep_)\n",
    "            the_parse.append((token.lemma_, token.tag_, sp.explain(token.tag_), token.pos_, token.dep_,k))\n",
    "            # The root is the main verb in the sentence\n",
    "            # if found_root:\n",
    "            #     break\n",
    "    return the_parse\n",
    "\n",
    "def get_lemma(token_parse):\n",
    "    return token_parse[0]\n",
    "\n",
    "def get_tag(token_parse):\n",
    "    return token_parse[1]\n",
    "\n",
    "def get_pos(token_parse):\n",
    "    return token_parse[3] \n",
    "\n",
    "def get_dep(token_parse):\n",
    "    return token_parse[4] \n",
    "\n",
    "p = run_parse(\"Is the bread objective or subjective?.\")\n",
    "print([get_lemma(z) for z in p])\n",
    "print([get_tag(z) for z in p])\n",
    "print([get_pos(z) for z in p])\n",
    "print([get_dep(z) for z in p])\n",
    "\n",
    "run_parse(\"Do the places look nice?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k,\tlemma,\ttag,\tpos,\tdep\n",
      "0,\tdo,\tVBD,\tAUX,\taux\n",
      "1,\tyou,\tPRP,\tPRON,\tnsubj\n",
      "2,\tgo,\tVB,\tVERB,\tROOT\n",
      "3,\tto,\tIN,\tADP,\tprep\n",
      "4,\tthe,\tDT,\tDET,\tdet\n",
      "5,\tgood,\tJJS,\tADJ,\tamod\n",
      "6,\tplace,\tNNS,\tNOUN,\tpobj\n",
      "7,\t?,\t.,\tPUNCT,\tpunct\n",
      "k,\tlemma,\ttag,\tpos,\tdep\n",
      "0,\tdo,\tVBP,\tAUX,\taux\n",
      "1,\tn't,\tRB,\tPART,\tneg\n",
      "2,\tthe,\tDT,\tDET,\tdet\n",
      "3,\ttree,\tNNS,\tNOUN,\tnsubj\n",
      "4,\tlook,\tVB,\tVERB,\tROOT\n",
      "5,\tnice,\tJJ,\tADJ,\tacomp\n",
      "6,\t?,\t.,\tPUNCT,\tpunct\n"
     ]
    }
   ],
   "source": [
    "def full_parse(the_sentence):\n",
    "    phrase = english_language(the_sentence)\n",
    "    print('k,\\tlemma,\\ttag,\\tpos,\\tdep')\n",
    "    for k, token in enumerate(phrase):\n",
    "        print(f'{k},\\t{token.lemma_},\\t{token.tag_},\\t{token.pos_},\\t{token.dep_}')\n",
    "\n",
    "#full_parse(\"Is the bread objective or subjective?.\")\n",
    "full_parse('Did you go to the best places?')\n",
    "full_parse(\"Don't the trees look nice?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'qlabel': 'WHQ', 'lemmas': ('what', 'be')}\n",
      "{'qlabel': 'WHQ', 'lemmas': ('who', 'become')}\n",
      "{'qlabel': 'WHQ', 'lemmas': ('how', 'be')}\n",
      "{'qlabel': 'WHQ', 'lemmas': ('how', 'be')}\n",
      "{'qlabel': 'WHQ', 'lemmas': ('how', 'do')}\n",
      "{'qlabel': 'WHQ', 'lemmas': ('how', 'be')}\n",
      "{'qlabel': 'WHQ', 'lemmas': ('which', 'be')}\n"
     ]
    }
   ],
   "source": [
    "# 1st rule -  inversion:  auxiliary followed by noun phase \n",
    "def wh_question(the_parse):\n",
    "    features = None # {'qlabel': None, 'lemmas': ()}\n",
    "    # Starts with a question word?\n",
    "    if (get_tag(the_parse[0]) in ('WP', 'WRB', 'WDT')) and (get_pos(the_parse[1]) in ('AUX', 'VERB')):\n",
    "        features = {'qlabel':'WHQ', 'lemmas': (get_lemma(the_parse[0]), get_lemma(the_parse[1]))}\n",
    "    return features\n",
    "\n",
    "print(wh_question(run_parse('What is the currency in use in the Netherlands?')))\n",
    "print(wh_question(run_parse('Who became king of Holland in 1806?')))\n",
    "print(wh_question(run_parse('How was the king of Holland in 1806?')))\n",
    "print(wh_question(run_parse('How tall was the king of Holland in 1806?')))\n",
    "print(wh_question(run_parse('How does king of Holland make money?')))\n",
    "print(wh_question(run_parse('How large are your teeth grandma?')))\n",
    "print(wh_question(run_parse('Which are the best places?')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'qlabel': 'DOQ', 'lemmas': ('do', 'you')}\n",
      "{'qlabel': 'DOQ', 'lemmas': ('do', 'place')}\n"
     ]
    }
   ],
   "source": [
    "def did_question(the_parse):\n",
    "    # When inversions are not used (Go you home?) the phrase is prefaced by did to make a question.\n",
    "    features =  None # {'qlabel': None, 'lemmas': ()}\n",
    "    if get_lemma(the_parse[0]) == 'do':\n",
    "        # pprint.pprint(the_parse)\n",
    "        # Look for a subject\n",
    "        for p in the_parse[1:]:\n",
    "            # print(f'p- {p}')\n",
    "            if (get_dep(p) == 'nsubj') and\\\n",
    "                (get_pos(p) in ('PRON', 'PROPN', 'NOUN')):\n",
    "                features = {'qlabel':'DOQ', 'lemmas': (get_lemma(the_parse[0]), get_lemma(p)) }\n",
    "    return features\n",
    "\n",
    "print(did_question(run_parse('Did you go to the best places?')))\n",
    "print(did_question(run_parse(\"Do the places look nice?\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'qlabel': 'QIS', 'lemmas': ('be', 'tree')}\n",
      "{'qlabel': 'QIS', 'lemmas': ('be', 'tree')}\n",
      "{'qlabel': 'QIS', 'lemmas': ('be', 'bread')}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def is_question(the_parse):\n",
    "    # The verb form 'be' placed before its subject indicates a question\n",
    "    # pprint.pprint(the_parse)\n",
    "    features = None  # {'qlabel': None, 'lemmas': ()}\n",
    "    # Starts with 'be' as the ROOT, followed by it's subject noun. \n",
    "    if (get_lemma(the_parse[0]) == 'be') and\\\n",
    "       (get_dep(the_parse[0]) in ('ROOT', 'AUX')):\n",
    "       # Look for a subject\n",
    "       for p in the_parse[1:]:\n",
    "          # print(f'p- {p}')\n",
    "          if (get_dep(p) == 'nsubj') and\\\n",
    "             (get_pos(p) in ('PRON', 'PROPN', 'NOUN')):\n",
    "             features = {'qlabel':'QIS', 'lemmas': (get_lemma(the_parse[0]), get_lemma(p)) }\n",
    "    return features\n",
    "\n",
    "print(is_question(run_parse(\"Aren't trees nice?\")))\n",
    "print(is_question(run_parse(\"Are the trees nice?\")))\n",
    "print(is_question(run_parse(\"is bread something Korean?\")))\n",
    "print(is_question(run_parse(\"Would it be better?\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'qlabel': 'QIS', 'lemmas': ('be', 'tree')}\n",
      "{'qlabel': 'QIS', 'lemmas': ('be', 'beauty')}\n",
      "{'qlabel': 'DOQ', 'lemmas': ('do', 'dinosaur')}\n",
      "{'qlabel': 'WHQ', 'lemmas': ('who', 'play')}\n",
      "{'qlabel': None, 'lemmas': ()}\n",
      "{'qlabel': None, 'lemmas': ()}\n"
     ]
    }
   ],
   "source": [
    "def tst_for_question(the_sentence):\n",
    "    'test for a question form, and if so, return its features'\n",
    "    # TODO Extend this to ignore a phrase that prefaces the question. (e.g. the question word is not first.)\n",
    "    \n",
    "    p = run_parse(the_sentence)\n",
    "    if feature := did_question(p):\n",
    "        pass\n",
    "    elif feature := is_question(p):\n",
    "        pass\n",
    "    elif feature := wh_question(p):\n",
    "        pass\n",
    "    else:\n",
    "        feature = {'qlabel': None, 'lemmas': ()}\n",
    "    return feature\n",
    "\n",
    "print(tst_for_question(\"Aren't trees nice?\"))\n",
    "print(tst_for_question('Is beauty objective or subjective?'))\n",
    "print(tst_for_question('Did dinosaurs have lips?'))\n",
    "print(tst_for_question('Who played Billy the Kid in The Left Handed Gun'))\n",
    "print(tst_for_question('Please summarize what Linkedin does.'))\n",
    "print(tst_for_question('Give me what you find.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse = [tst_for_question(instruction) for instruction in d_data.loc[ :, 'instruction']]\n",
    "p_data = pd.concat([pd.DataFrame(parse), d_data], axis=1)\n",
    "# p_data.columns = ['parse', 'instruction', 'context', 'response', 'category']\n",
    "#p_data #.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_data[['qlabel', 'lemmas', 'instruction','category']].to_csv('dolly-instruction_parse_15k.csv', na_rep='NULL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>category</th>\n",
       "      <th>brainstorming</th>\n",
       "      <th>classification</th>\n",
       "      <th>closed_qa</th>\n",
       "      <th>creative_writing</th>\n",
       "      <th>general_qa</th>\n",
       "      <th>information_extraction</th>\n",
       "      <th>open_qa</th>\n",
       "      <th>summarization</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qlabel</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DOQ</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NQ</th>\n",
       "      <td>970</td>\n",
       "      <td>1835</td>\n",
       "      <td>1006</td>\n",
       "      <td>480</td>\n",
       "      <td>459</td>\n",
       "      <td>942</td>\n",
       "      <td>851</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QIS</th>\n",
       "      <td>22</td>\n",
       "      <td>42</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>78</td>\n",
       "      <td>13</td>\n",
       "      <td>72</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHQ</th>\n",
       "      <td>770</td>\n",
       "      <td>257</td>\n",
       "      <td>711</td>\n",
       "      <td>207</td>\n",
       "      <td>1623</td>\n",
       "      <td>543</td>\n",
       "      <td>2785</td>\n",
       "      <td>589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "category  brainstorming  classification  closed_qa  creative_writing  \\\n",
       "qlabel                                                                 \n",
       "DOQ                   4               2         21                11   \n",
       "NQ                  970            1835       1006               480   \n",
       "QIS                  22              42         35                11   \n",
       "WHQ                 770             257        711               207   \n",
       "\n",
       "category  general_qa  information_extraction  open_qa  summarization  \n",
       "qlabel                                                                \n",
       "DOQ               31                       8       34              5  \n",
       "NQ               459                     942      851            570  \n",
       "QIS               78                      13       72             24  \n",
       "WHQ             1623                     543     2785            589  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To continue with the saved data\n",
    "p_data = pd.read_csv('dolly-instruction_parse_15k.csv')\n",
    "p_data.fillna('NQ', inplace=True)                        # Not a question. \n",
    "pd.crosstab(p_data['qlabel'], p_data['category'])\n",
    "# Note that the correlation between category labels and if it is a question is not strong. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DOQ', 'NQ', 'QIS', 'WHQ'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(p_data['qlabel'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
