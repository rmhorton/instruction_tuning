{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df = pd.read_parquet('./data/race_test_prepared.parquet')\n",
    "race_df = race_df[race_df['fk_score'] <= 15]\n",
    "race_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_regression_with_cv(df, embeddings_col, y_col):\n",
    "    X = np.array(df[embeddings_col].tolist())\n",
    "    X = X / np.linalg.norm(X, axis=1, keepdims=True)\n",
    "    \n",
    "    y = df[y_col].values\n",
    "    \n",
    "    kf = KFold(n_splits=7, shuffle=True, random_state=369)\n",
    "    \n",
    "    best_model = None\n",
    "    best_error = float('inf')\n",
    "    \n",
    "    for train_index, val_index in kf.split(df):\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "        \n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        predictions = model.predict(X_val)\n",
    "        error = mean_squared_error(y_val, predictions)\n",
    "        \n",
    "        if error < best_error:\n",
    "            best_error = error\n",
    "            best_model = model\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = train_linear_regression_with_cv(df=race_df, embeddings_col='embeddings_mini_lm', y_col='fk_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(df, clf, embeddings_col, y_col):\n",
    "    X = np.array(df[embeddings_col].tolist())\n",
    "    X = X / np.linalg.norm(X, axis=1, keepdims=True)\n",
    "    \n",
    "    y = df[y_col].values\n",
    "\n",
    "    y_pred = clf.predict(X)\n",
    "\n",
    "    print('MSE:', mean_squared_error(y, y_pred))\n",
    "    print('MAE:', mean_absolute_error(y, y_pred))\n",
    "    print('R2:', r2_score(y, y_pred))\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.scatterplot(x=y, y=y_pred)\n",
    "    plt.xlabel('True Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_predictions(df=race_df, clf=clf, embeddings_col='embeddings_mini_lm', y_col='fk_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# race_df['score_easy'] = clf.predict_proba(X=np.array(race_df['embeddings_mini_lm'].tolist()))[:,0]\n",
    "# race_df['score_hard'] = clf.predict_proba(X=np.array(race_df['embeddings_mini_lm'].tolist()))[:,1]\n",
    "# race_df['score_medium'] = clf.predict_proba(X=np.array(race_df['embeddings_mini_lm'].tolist()))[:,2]\n",
    "\n",
    "# race_df['w_easy_embeddings'] = race_df['embeddings_mini_lm'].apply(lambda x: x * clf.coef_[0])\n",
    "# race_df['w_hard_embeddings'] = race_df['embeddings_mini_lm'].apply(lambda x: x * clf.coef_[1])\n",
    "# race_df['w_medium_embeddings'] = race_df['embeddings_mini_lm'].apply(lambda x: x * clf.coef_[2])\n",
    "# race_df['iw_easy_embeddings'] = race_df['embeddings_mini_lm'].apply(lambda x: x / clf.coef_[0])\n",
    "# race_df['iw_hard_embeddings'] = race_df['embeddings_mini_lm'].apply(lambda x: x / clf.coef_[1])\n",
    "# race_df['iw_medium_embeddings'] = race_df['embeddings_mini_lm'].apply(lambda x: x / clf.coef_[2])\n",
    "\n",
    "race_df['score'] = clf.predict(X=np.array(race_df['embeddings_mini_lm'].tolist()))\n",
    "race_df['absolute_error'] = np.abs(np.array(race_df['fk_score']) - clf.predict(X=np.array(race_df['embeddings_mini_lm'].tolist())))\n",
    "race_df['w_embeddings'] = race_df['embeddings_mini_lm'].apply(lambda x: x * clf.coef_)\n",
    "race_df['iw_embeddings'] = race_df['embeddings_mini_lm'].apply(lambda x: x / clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_stats(df, cluster_col, score_col):\n",
    "    return df.groupby(cluster_col).agg(\n",
    "        score_mean=pd.NamedAgg(column=score_col, aggfunc='mean'), \n",
    "        score_std =pd.NamedAgg(column=score_col, aggfunc='std')\n",
    "    ).reset_index(drop=False).rename(columns={cluster_col: 'cluster_id'})\n",
    "\n",
    "n_clusters = 20\n",
    "seed=0\n",
    "uw_kmeans = KMeans(n_clusters=n_clusters, random_state=seed, n_init=\"auto\").fit( [v for v in race_df['embeddings_mini_lm']])\n",
    "w_kmeans = KMeans(n_clusters=n_clusters, random_state=seed, n_init=\"auto\").fit( [v for v in race_df['w_embeddings']])\n",
    "iw_kmeans = KMeans(n_clusters=n_clusters, random_state=seed, n_init=\"auto\").fit( [v for v in race_df['iw_embeddings']])\n",
    "\n",
    "race_df['uw_kmeans'] = uw_kmeans.labels_\n",
    "race_df['w_kmeans'] = w_kmeans.labels_\n",
    "race_df['iw_kmeans'] = iw_kmeans.labels_\n",
    "\n",
    "# cs_unweighted = get_cluster_stats(dd2, 'unweighted_kmeans', 'score')\n",
    "# cs_weighted = get_cluster_stats(dd2, 'weighted_kmeans', 'score')\n",
    "# cs_inverse_weighted = get_cluster_stats(dd2, 'inverse_weighted_kmeans', 'score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df = race_df[['uw_kmeans', 'w_kmeans', 'iw_kmeans', 'score', 'absolute_error']]\n",
    "cluster_df = pd.melt(cluster_df, id_vars=['score', 'absolute_error'], var_name='weighting', value_name='cluster_id')\n",
    "cluster_df = cluster_df.groupby(['weighting', 'cluster_id']).agg({'score': ['mean', 'var'], 'absolute_error': ['mean', 'var']}).reset_index()\n",
    "cluster_df.columns = ['weighting', 'cluster_id', 'mean_score', 'var_score', 'mean_absolute_error', 'var_absolute_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\":(5, 3)})\n",
    "fig, axes = plt.subplots(2, 1, sharey=True)\n",
    "\n",
    "sns.stripplot(x='mean_score', y='weighting', data=cluster_df, jitter=True, hue='weighting', dodge=True, ax=axes[0])\n",
    "axes[0].legend(loc='upper right', bbox_to_anchor=(1.5, 1))\n",
    "axes[0].set(ylabel=None)\n",
    "axes[0].set(xticklabels=[])\n",
    "axes[0].set(xlabel=None)\n",
    "\n",
    "sns.boxplot(x='mean_score', y ='weighting', data=cluster_df, hue='weighting', dodge=True, ax=axes[1])\n",
    "axes[1].set(ylabel=None)\n",
    "axes[1].set(xlabel='Mean Score by Cluster')\n",
    "axes[1].legend([], [], frameon=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\":(5, 3)})\n",
    "fig, axes = plt.subplots(2, 1, sharey=True)\n",
    "\n",
    "sns.stripplot(x='var_score', y='weighting', data=cluster_df, jitter=True, hue='weighting', dodge=True, ax=axes[0])\n",
    "axes[0].legend(loc='upper right', bbox_to_anchor=(1.5, 1))\n",
    "axes[0].set(ylabel=None)\n",
    "axes[0].set(xticklabels=[])\n",
    "axes[0].set(xlabel=None)\n",
    "\n",
    "sns.boxplot(x='var_score', y ='weighting', data=cluster_df, hue='weighting', dodge=True, ax=axes[1])\n",
    "axes[1].set(ylabel=None)\n",
    "axes[1].set(xlabel='Variance of Scores by Cluster')\n",
    "axes[1].legend([], [], frameon=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\":(5, 3)})\n",
    "fig, axes = plt.subplots(2, 1, sharey=True)\n",
    "\n",
    "sns.stripplot(x='mean_absolute_error', y='weighting', data=cluster_df, jitter=True, hue='weighting', dodge=True, ax=axes[0])\n",
    "axes[0].legend(loc='upper right', bbox_to_anchor=(1.5, 1))\n",
    "axes[0].set(ylabel=None)\n",
    "axes[0].set(xticklabels=[])\n",
    "axes[0].set(xlabel=None)\n",
    "\n",
    "sns.boxplot(x='mean_absolute_error', y ='weighting', data=cluster_df, hue='weighting', dodge=True, ax=axes[1])\n",
    "axes[1].set(ylabel=None)\n",
    "axes[1].set(xlabel='Mean Absolute Error by Cluster')\n",
    "axes[1].legend([], [], frameon=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\":(5, 3)})\n",
    "fig, axes = plt.subplots(2, 1, sharey=True)\n",
    "\n",
    "sns.stripplot(x='var_absolute_error', y='weighting', data=cluster_df, jitter=True, hue='weighting', dodge=True, ax=axes[0])\n",
    "axes[0].legend(loc='upper right', bbox_to_anchor=(1.5, 1))\n",
    "axes[0].set(ylabel=None)\n",
    "axes[0].set(xticklabels=[])\n",
    "axes[0].set(xlabel=None)\n",
    "\n",
    "sns.boxplot(x='var_absolute_error', y ='weighting', data=cluster_df, hue='weighting', dodge=True, ax=axes[1])\n",
    "axes[1].set(ylabel=None)\n",
    "axes[1].set(xlabel='Variance of Absolute Errors by Cluster')\n",
    "axes[1].legend([], [], frameon=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df['fk_score'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(race_df[race_df['fk_score'] <= 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_embedding = np.mean(race_df[race_df['fk_score'] <= 4]['embeddings_mini_lm'])\n",
    "\n",
    "# optionally weight the aspect embeddings with the classifier / regression model coefficients\n",
    "aspect_embedding = aspect_embedding * clf.coef_\n",
    "\n",
    "aspect_embedding = aspect_embedding / np.linalg.norm(aspect_embedding)\n",
    "\n",
    "race_df['w_embeddings'] = race_df['embeddings_mini_lm']\n",
    "race_df['iw_embeddings'] = race_df['embeddings_mini_lm']\n",
    "\n",
    "alpha = 2\n",
    "for i, embedding in enumerate(race_df['embeddings_mini_lm']):\n",
    "    embedding = embedding / np.linalg.norm(embedding)\n",
    "    projection = np.dot(embedding, aspect_embedding.T) * aspect_embedding\n",
    "    projection = projection.reshape(-1,)\n",
    "    race_df['w_embeddings'].iloc[i] = embedding + alpha * projection\n",
    "    race_df['iw_embeddings'].iloc[i] = embedding - alpha * projection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 40\n",
    "seed=0\n",
    "uw_kmeans = KMeans(n_clusters=n_clusters, random_state=seed, n_init=\"auto\").fit( [v for v in race_df['embeddings_mini_lm']])\n",
    "w_kmeans = KMeans(n_clusters=n_clusters, random_state=seed, n_init=\"auto\").fit( [v for v in race_df['w_embeddings']])\n",
    "iw_kmeans = KMeans(n_clusters=n_clusters, random_state=seed, n_init=\"auto\").fit( [v for v in race_df['iw_embeddings']])\n",
    "\n",
    "race_df['uw_kmeans'] = uw_kmeans.labels_\n",
    "race_df['w_kmeans'] = w_kmeans.labels_\n",
    "race_df['iw_kmeans'] = iw_kmeans.labels_\n",
    "\n",
    "cluster_df = race_df[['uw_kmeans', 'w_kmeans', 'iw_kmeans', 'score', 'absolute_error']]\n",
    "cluster_df = pd.melt(cluster_df, id_vars=['score', 'absolute_error'], var_name='weighting', value_name='cluster_id')\n",
    "cluster_df = cluster_df.groupby(['weighting', 'cluster_id']).agg({'score': ['mean', 'var'], 'absolute_error': ['mean', 'var']}).reset_index()\n",
    "cluster_df.columns = ['weighting', 'cluster_id', 'mean_score', 'var_score', 'mean_absolute_error', 'var_absolute_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\":(5, 3)})\n",
    "fig, axes = plt.subplots(2, 1, sharey=True)\n",
    "\n",
    "sns.stripplot(x='mean_score', y='weighting', data=cluster_df, jitter=True, hue='weighting', dodge=True, ax=axes[0])\n",
    "axes[0].legend(loc='upper right', bbox_to_anchor=(1.5, 1))\n",
    "axes[0].set(ylabel=None)\n",
    "axes[0].set(xticklabels=[])\n",
    "axes[0].set(xlabel=None)\n",
    "\n",
    "sns.boxplot(x='mean_score', y ='weighting', data=cluster_df, hue='weighting', dodge=True, ax=axes[1])\n",
    "axes[1].set(ylabel=None)\n",
    "axes[1].set(xlabel='Mean Score by Cluster')\n",
    "axes[1].legend([], [], frameon=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\":(5, 3)})\n",
    "fig, axes = plt.subplots(2, 1, sharey=True)\n",
    "\n",
    "sns.stripplot(x='var_score', y='weighting', data=cluster_df, jitter=True, hue='weighting', dodge=True, ax=axes[0])\n",
    "axes[0].legend(loc='upper right', bbox_to_anchor=(1.5, 1))\n",
    "axes[0].set(ylabel=None)\n",
    "axes[0].set(xticklabels=[])\n",
    "axes[0].set(xlabel=None)\n",
    "\n",
    "sns.boxplot(x='var_score', y ='weighting', data=cluster_df, hue='weighting', dodge=True, ax=axes[1])\n",
    "axes[1].set(ylabel=None)\n",
    "axes[1].set(xlabel='Variance of Scores by Cluster')\n",
    "axes[1].legend([], [], frameon=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
