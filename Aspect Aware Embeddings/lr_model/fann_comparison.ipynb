{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# See github.com/hora-search/horapy\n",
    "try:\n",
    "    import horapy\n",
    "except:\n",
    "    os.system('pip install horapy')\n",
    "    \n",
    "from horapy import HNSWIndex\n",
    "\n",
    "from numpy.random import Generator, PCG64\n",
    "rng = Generator(PCG64())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast Approximate NN performance comparison\n",
    "\n",
    "A first cut of the retrieval times for one current FANN implementation compared to brute force linear search in a dataset of embedding vectors.  The example uses the IMDB data set as indexed by embeddings from the 'all-MiniLM-L6-v2' sentenceTransformer model---a set of 50,000 items of 384 features. \n",
    "\n",
    "tl;dr - Linear search (and sorting also) on this \"small\" set are so fast that it would be hard to beat the timings of brute force code.\n",
    "\n",
    "JMA Feb 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the existing IMDB vectorized data\n",
    "DATA_DIR = '/mnt/512G_hd/data/IMDB/'\n",
    "text_df = pd.read_parquet(DATA_DIR + 'IMDB_sentiment.parquet') \n",
    "    \n",
    "print(text_df.shape)\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the vector field and expand it to multiple rows. \n",
    "n_samples, embedding_dim = text_df.shape\n",
    "sample_ar = np.empty((n_samples, 384), 'float')\n",
    "for i in range(n_samples):\n",
    "    x = text_df.values[i,2]\n",
    "    sample_ar[i] = x # [np.newaxis,:]    # Works but adding the dimension isn't necessary\n",
    "    \n",
    "sample_ar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select one item as a target, and build an index to find distances\n",
    "\n",
    "n_samples, em_dimension = sample_ar.shape\n",
    "\n",
    "embedding_index = HNSWIndex(em_dimension, \"usize\")\n",
    "\n",
    "target = rng.choice(n_samples)\n",
    "\n",
    "for i in range(n_samples):\n",
    "    if i != target:\n",
    "        # Add an embedding vector to the index\n",
    "        a_sample = np.float32(sample_ar[i,:])\n",
    "        # print(a_sample.shape, type(a_sample))\n",
    "        embedding_index.add(a_sample,i)\n",
    "    else:\n",
    "        chosen = np.float32(sample_ar[i,:])\n",
    "        \n",
    "embedding_index.build('euclidean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y = embedding_index.search(chosen,49999)\n",
    "# Lookup all samples in order of distance \n",
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "distances = np.empty((n_samples,))\n",
    "\n",
    "for i in range(n_samples):\n",
    "    distances[i] = np.dot(chosen, sample_ar[i])\n",
    "# Making a comparison with just running a linear traversal via dot products through the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "d2 = distances.copy()\n",
    "d2.sort()\n",
    "d2[:-10]\n",
    "# Comparison - to be fair the time to sort the distances should be counted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range of dot product values\n",
    "pd.DataFrame(distances).describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
