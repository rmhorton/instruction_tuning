{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# See github.com/hora-search/horapy\n",
    "try:\n",
    "    import horapy\n",
    "except:\n",
    "    os.system('pip install horapy')\n",
    "    \n",
    "from horapy import HNSWIndex\n",
    "\n",
    "from numpy.random import Generator, PCG64\n",
    "rng = Generator(PCG64())"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": 2,
=======
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": 2,
=======
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast Approximate NN performance comparison\n",
    "\n",
    "A first cut of the retrieval times for one current FANN implementation compared to brute force linear search in a dataset of embedding vectors.  The example uses the IMDB data set as indexed by embeddings from the 'all-MiniLM-L6-v2' sentenceTransformer model---a set of 50,000 items of 384 features. \n",
    "\n",
    "tl;dr - Linear search (and sorting also) on this \"small\" set are so fast that it would be hard to beat the timings of brute force code.\n",
    "\n",
    "JMA Feb 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
>>>>>>> 19af028 (fann comparison)
>>>>>>> d83ffd8 (fann comparison)
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[0.030099334195256233, 0.05041766166687012, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[-0.012201831676065922, 0.05196141451597214, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[0.014258116483688354, -0.0791383683681488, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[-0.04172040894627571, 0.010464057326316833, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[-0.03167528286576271, 0.00642423564568162, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  One of the other reviewers has mentioned that ...  positive   \n",
       "1  A wonderful little production. <br /><br />The...  positive   \n",
       "2  I thought this was a wonderful way to spend ti...  positive   \n",
       "3  Basically there's a family where a little boy ...  negative   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
       "\n",
       "                                              vector  \n",
       "0  [0.030099334195256233, 0.05041766166687012, -0...  \n",
       "1  [-0.012201831676065922, 0.05196141451597214, -...  \n",
       "2  [0.014258116483688354, -0.0791383683681488, 0....  \n",
       "3  [-0.04172040894627571, 0.010464057326316833, -...  \n",
       "4  [-0.03167528286576271, 0.00642423564568162, -0...  "
      ]
     },
<<<<<<< HEAD
     "execution_count": 2,
=======
<<<<<<< HEAD
     "execution_count": 2,
=======
     "execution_count": 31,
>>>>>>> 19af028 (fann comparison)
>>>>>>> d83ffd8 (fann comparison)
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the existing IMDB vectorized data\n",
    "DATA_DIR = '/mnt/512G_hd/data/IMDB/'\n",
    "text_df = pd.read_parquet(DATA_DIR + 'IMDB_sentiment.parquet') \n",
    "    \n",
    "print(text_df.shape)\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 32,
>>>>>>> 19af028 (fann comparison)
>>>>>>> d83ffd8 (fann comparison)
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 384)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 3,
=======
<<<<<<< HEAD
     "execution_count": 3,
=======
     "execution_count": 32,
>>>>>>> 19af028 (fann comparison)
>>>>>>> d83ffd8 (fann comparison)
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
=======
<<<<<<< HEAD
=======
    "# Extract the vector field and expand it to multiple rows. \n",
>>>>>>> 19af028 (fann comparison)
>>>>>>> d83ffd8 (fann comparison)
    "n_samples, embedding_dim = text_df.shape\n",
    "sample_ar = np.empty((n_samples, 384), 'float')\n",
    "for i in range(n_samples):\n",
    "    x = text_df.values[i,2]\n",
<<<<<<< HEAD
    "    sample_ar[i] = x[np.newaxis,:]\n",
=======
<<<<<<< HEAD
    "    sample_ar[i] = x[np.newaxis,:]\n",
=======
    "    sample_ar[i] = x # [np.newaxis,:]    # Works but adding the dimension isn't necessary\n",
>>>>>>> 19af028 (fann comparison)
>>>>>>> d83ffd8 (fann comparison)
    "    \n",
    "sample_ar.shape"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
=======
<<<<<<< HEAD
>>>>>>> d83ffd8 (fann comparison)
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 50, numpy.ndarray)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_ar1 = np.float32(np.random.rand(1000, 50))\n",
    "\n",
    "n_samples, em_dimension = sample_ar1.shape\n",
    "n_samples, em_dimension, type(sample_ar1[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[23481, 27493, 6581, 25374, 5780, 32159, 10000, 9403, 16256, 41433]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select one item as a target.\n",
    "\n",
    "import numpy as np\n",
    "from horapy import HNSWIndex\n",
    "# dimension = 50\n",
    "# n = 1000\n",
    "\n",
    "# sample_ar1 = np.float32(np.random.rand(n, dimension))\n",
<<<<<<< HEAD
=======
=======
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select one item as a target, and build an index to find distances\n",
    "\n",
>>>>>>> 19af028 (fann comparison)
>>>>>>> d83ffd8 (fann comparison)
    "n_samples, em_dimension = sample_ar.shape\n",
    "\n",
    "embedding_index = HNSWIndex(em_dimension, \"usize\")\n",
    "\n",
    "target = rng.choice(n_samples)\n",
    "\n",
<<<<<<< HEAD
    "for i in range(0, n_samples):\n",
=======
<<<<<<< HEAD
    "for i in range(0, n_samples):\n",
=======
    "for i in range(n_samples):\n",
>>>>>>> 19af028 (fann comparison)
>>>>>>> d83ffd8 (fann comparison)
    "    if i != target:\n",
    "        # Add an embedding vector to the index\n",
    "        a_sample = np.float32(sample_ar[i,:])\n",
    "        # print(a_sample.shape, type(a_sample))\n",
    "        embedding_index.add(a_sample,i)\n",
    "    else:\n",
    "        chosen = np.float32(sample_ar[i,:])\n",
    "        \n",
<<<<<<< HEAD
    "embedding_index.build('euclidean')\n",
    "embedding_index.search(chosen,10)"
=======
<<<<<<< HEAD
    "embedding_index.build('euclidean')\n",
    "embedding_index.search(chosen,10)"
=======
    "embedding_index.build('euclidean')\n"
>>>>>>> 19af028 (fann comparison)
>>>>>>> d83ffd8 (fann comparison)
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
=======
<<<<<<< HEAD
>>>>>>> d83ffd8 (fann comparison)
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, numpy.ndarray, 829, 50, 50)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i, type(chosen), target, len(chosen), len(np.float32(sample_ar1[target,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
<<<<<<< HEAD
=======
=======
   "execution_count": 34,
>>>>>>> 19af028 (fann comparison)
>>>>>>> d83ffd8 (fann comparison)
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
=======
<<<<<<< HEAD
>>>>>>> d83ffd8 (fann comparison)
      "shape (1000, 50)\n",
      "<class 'numpy.ndarray'>\n",
      "target 671\n",
      "\n",
      "671 in Hora ANNIndex <HNSWIndexUsize> (dimension: 50, dtype: usize, max_item: 1000000, n_neigh: 32, n_neigh0: 64, ef_build: 20, ef_search: 500, has_deletion: False) \n",
      "has neighbors: [671, 909, 679, 774, 678, 758, 222, 556, 485, 468]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from horapy import HNSWIndex\n",
    "\n",
    "dimension = 50\n",
    "n = 1000\n",
    "\n",
    "# init index instance\n",
    "index = HNSWIndex(dimension, \"usize\")\n",
    "\n",
    "samples = np.float32(np.random.rand(n, dimension))\n",
    "print(f'shape {samples.shape}')\n",
    "print(type(samples[0,:]))\n",
    "for i in range(0, len(samples)):\n",
    "    # add node\n",
    "    x = np.float32(samples[i])\n",
    "    # print(type(x), x.shape)\n",
    "    index.add(x, i)\n",
    "\n",
    "index.build(\"euclidean\")  # build index\n",
    "\n",
    "target = np.random.randint(0, n)\n",
    "print(f'target {target}')\n",
    "# 410 in Hora ANNIndex <HNSWIndexUsize> (dimension: 50, dtype: usize, max_item: 1000000, n_neigh: 32, n_neigh0: 64, ef_build: 20, ef_search: 500, has_deletion: False)\n",
    "# has neighbors: [410, 736, 65, 36, 631, 83, 111, 254, 990, 161]\n",
    "print(\"\\n{} in {} \\nhas neighbors: {}\".format(\n",
    "    target, index, index.search(samples[target], 10)))  # search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 78,
<<<<<<< HEAD
=======
=======
      "CPU times: user 128 ms, sys: 24.1 ms, total: 152 ms\n",
      "Wall time: 151 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[45533, 304, 13891, 20164, 37985, 15981, 18052, 8472, 40965, 34112]"
      ]
     },
     "execution_count": 34,
>>>>>>> 19af028 (fann comparison)
>>>>>>> d83ffd8 (fann comparison)
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "len(samples)"
=======
<<<<<<< HEAD
    "len(samples)"
=======
    "%%time\n",
    "y = embedding_index.search(chosen,49999)\n",
    "# Lookup all samples in order of distance \n",
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 104 ms, sys: 0 ns, total: 104 ms\n",
      "Wall time: 102 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "distances = np.empty((n_samples,))\n",
    "\n",
    "for i in range(n_samples):\n",
    "    distances[i] = np.dot(chosen, sample_ar[i])\n",
    "# Making a comparison with just running a linear traversal via dot products through the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.86 ms, sys: 54 µs, total: 6.92 ms\n",
      "Wall time: 6.02 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.11729608, -0.11559604, -0.10119724, ...,  0.63621736,\n",
       "        0.63796331,  0.63799412])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "d2 = distances.copy()\n",
    "d2.sort()\n",
    "d2[:-10]\n",
    "# Comparison - to be fair the time to sort the distances should be counted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.319930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.097288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.117296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.259063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.327565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.388124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  50000.000000\n",
       "mean       0.319930\n",
       "std        0.097288\n",
       "min       -0.117296\n",
       "25%        0.259063\n",
       "50%        0.327565\n",
       "75%        0.388124\n",
       "max        1.000000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Range of dot product values\n",
    "pd.DataFrame(distances).describe()"
>>>>>>> 19af028 (fann comparison)
>>>>>>> d83ffd8 (fann comparison)
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
