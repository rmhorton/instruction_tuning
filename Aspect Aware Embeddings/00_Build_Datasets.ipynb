{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_template = \"\"\"### CONTEXT ###\n",
    "{context}\n",
    "\n",
    "### QUESTION ###\n",
    "{question}\n",
    "\n",
    "### ANSWER ###\n",
    "{answer}\n",
    "\"\"\"\n",
    "\n",
    "def get_text(context, question, answer):\n",
    "    return text_template.format(context=context, question=question, answer=answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dolly_ds = load_dataset('databricks/databricks-dolly-15k')\n",
    "\n",
    "dolly_cqa = dolly_ds['train'].filter(lambda row: row['category'] == 'closed_qa')\n",
    "dolly_cqa_df = dolly_cqa.to_pandas()\n",
    "\n",
    "dolly_cqa_df['text'] = dolly_cqa_df.apply(lambda x: get_text(context=x['context'], question=x['instruction'], answer=x['response']), axis=1)\n",
    "\n",
    "dolly_cqa_df.to_csv('./data/dolly_cqa.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dolly_cqa_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_race_df(datasets, subsets, split, difficulties, sample_size):\n",
    "    race_datasets = []\n",
    "    for ds, ss in zip(datasets, subsets):\n",
    "        if ss != None:\n",
    "            race = load_dataset(ds, ss, split=split)\n",
    "        else:\n",
    "            race = load_dataset(ds, split=split)\n",
    "        race_datasets.append(race)\n",
    "\n",
    "    columns = ['example_id', 'article', 'answer', 'question', 'options']\n",
    "    race_df = pd.DataFrame()\n",
    "    for i, ds in enumerate(race_datasets):\n",
    "        df = ds.to_pandas()\n",
    "        if list(df.columns) != columns:\n",
    "            df.columns = ['options', 'question', 'article', 'example_id', 'answer']\n",
    "        df['difficulty'] = difficulties[i]\n",
    "        df = df.sample(sample_size)\n",
    "        race_df= race_df.append(df)\n",
    "\n",
    "    mapping = {'A': '0', 'B': '1', 'C': '2', 'D': '3'}\n",
    "    race_df['answer'] = race_df['answer'].replace(mapping)\n",
    "    \n",
    "    race_df = race_df.reset_index(drop=True)\n",
    "    race_df['text'] = race_df.apply(lambda x: get_text(context=x['article'], question=x['question'], answer=x['options'][int(x['answer'])]), axis=1)\n",
    "    \n",
    "    # race_df['options'] = race_df['options'].apply(lambda x: x.tolist())\n",
    "    return race_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df_train = build_race_df(datasets=['race', 'race', 'metaeval/race-c'], subsets=['middle', 'high', None], split='train',\n",
    "                              difficulties=['M', 'H', 'C'], sample_size=12702)\n",
    "\n",
    "race_df_validation = build_race_df(datasets=['race', 'race', 'metaeval/race-c'], subsets=['middle', 'high', None], split='validation',\n",
    "                                   difficulties=['M', 'H', 'C'], sample_size=712)\n",
    "\n",
    "race_df_test = build_race_df(datasets=['race', 'race', 'metaeval/race-c'], subsets=['middle', 'high', None], split='test',\n",
    "                             difficulties=['M', 'H', 'C'], sample_size=708)\n",
    "\n",
    "race_df_train.to_csv('./data/race_train.csv', index=False)\n",
    "race_df_validation.to_csv('./data/race_validation.csv', index=False)\n",
    "race_df_test.to_csv('./data/race_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
