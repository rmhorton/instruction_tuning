{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df = pd.read_parquet('./data/race_train_prepared.parquet')\n",
    "race_df = race_df[race_df['fk_score_categ'] != 'medium']\n",
    "race_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lr_classifier(df, embeddings_col, y_col):\n",
    "    # Convert the list of lists in X_colname to a numpy array\n",
    "    X = np.array(df[embeddings_col].tolist())\n",
    "    \n",
    "    y = df[y_col]\n",
    "    \n",
    "    # Label encoding the target variable\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    \n",
    "    # Initialize LR classifier\n",
    "    clf = LogisticRegressionCV(cv=5, scoring='f1_macro', max_iter=10000, n_jobs=-1)\n",
    "    # clf = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=10000)\n",
    "\n",
    "    # Fit the classifier\n",
    "    clf.fit(X, y_encoded)\n",
    "\n",
    "    return le, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le, clf = train_lr_classifier(df=race_df, embeddings_col='embeddings_mini_lm', y_col='fk_score_categ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(df, le, clf, embeddings_col, y_col):\n",
    "    # Convert the list of lists in X_colname to a numpy array\n",
    "    X = np.array(df[embeddings_col].tolist())\n",
    "    \n",
    "    y = df[y_col]\n",
    "\n",
    "    # Label encoding the target variable\n",
    "    y_encoded = le.transform(y)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred_encoded = clf.predict(X)\n",
    "\n",
    "    # Reverse-transform the predicted and actual labels to their original values\n",
    "    y_pred = le.inverse_transform(y_pred_encoded)\n",
    "    y_test = le.inverse_transform(y_encoded)\n",
    "\n",
    "    # Printing the classification report\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Plotting the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(7,5))\n",
    "    sns.heatmap(cm, annot=True, fmt='g', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_predictions(df=race_df, le=le, clf=clf, embeddings_col='embeddings_mini_lm', y_col='fk_score_categ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# race_df['score_easy'] = clf.predict_proba(X=np.array(race_df['embeddings_mini_lm'].tolist()))[:,0]\n",
    "# race_df['score_hard'] = clf.predict_proba(X=np.array(race_df['embeddings_mini_lm'].tolist()))[:,1]\n",
    "# race_df['score_medium'] = clf.predict_proba(X=np.array(race_df['embeddings_mini_lm'].tolist()))[:,2]\n",
    "\n",
    "# race_df['w_easy_embeddings'] = race_df['embeddings_mini_lm'].apply(lambda x: x * clf.coef_[0])\n",
    "# race_df['w_hard_embeddings'] = race_df['embeddings_mini_lm'].apply(lambda x: x * clf.coef_[1])\n",
    "# race_df['w_medium_embeddings'] = race_df['embeddings_mini_lm'].apply(lambda x: x * clf.coef_[2])\n",
    "# race_df['iw_easy_embeddings'] = race_df['embeddings_mini_lm'].apply(lambda x: x / clf.coef_[0])\n",
    "# race_df['iw_hard_embeddings'] = race_df['embeddings_mini_lm'].apply(lambda x: x / clf.coef_[1])\n",
    "# race_df['iw_medium_embeddings'] = race_df['embeddings_mini_lm'].apply(lambda x: x / clf.coef_[2])\n",
    "\n",
    "race_df['score'] = clf.predict_proba(X=np.array(race_df['embeddings_mini_lm'].tolist()))[:,1]\n",
    "race_df['w_embeddings'] = race_df['embeddings_mini_lm'].apply(lambda x: x * clf.coef_[0])\n",
    "race_df['iw_embeddings'] = race_df['embeddings_mini_lm'].apply(lambda x: x / clf.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_stats(df, cluster_col, score_col):\n",
    "    return df.groupby(cluster_col).agg(\n",
    "        score_mean=pd.NamedAgg(column=score_col, aggfunc='mean'), \n",
    "        score_std =pd.NamedAgg(column=score_col, aggfunc='std')\n",
    "    ).reset_index(drop=False).rename(columns={cluster_col: 'cluster_id'})\n",
    "\n",
    "n_clusters = 20\n",
    "seed=0\n",
    "uw_kmeans = KMeans(n_clusters=n_clusters, random_state=seed, n_init=\"auto\").fit( [v for v in race_df['embeddings_mini_lm']])\n",
    "w_kmeans = KMeans(n_clusters=n_clusters, random_state=seed, n_init=\"auto\").fit( [v for v in race_df['w_embeddings']])\n",
    "iw_kmeans = KMeans(n_clusters=n_clusters, random_state=seed, n_init=\"auto\").fit( [v for v in race_df['iw_embeddings']])\n",
    "\n",
    "race_df['uw_kmeans'] = uw_kmeans.labels_\n",
    "race_df['w_kmeans'] = w_kmeans.labels_\n",
    "race_df['iw_kmeans'] = iw_kmeans.labels_\n",
    "\n",
    "# cs_unweighted = get_cluster_stats(dd2, 'unweighted_kmeans', 'score')\n",
    "# cs_weighted = get_cluster_stats(dd2, 'weighted_kmeans', 'score')\n",
    "# cs_inverse_weighted = get_cluster_stats(dd2, 'inverse_weighted_kmeans', 'score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df = race_df[['uw_kmeans', 'w_kmeans', 'iw_kmeans', 'score']]\n",
    "cluster_df = pd.melt(cluster_df, id_vars=['score'], var_name='weighting', value_name='cluster_id')\n",
    "cluster_df = cluster_df.groupby([\"weighting\", \"cluster_id\"]).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\":(5, 1)})\n",
    "ax = sns.stripplot(x='score', y='weighting', data=cluster_df, jitter=True, hue='weighting', dodge=True, legend=False)\n",
    "ax.set(ylabel=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df[['weighting', 'score']].groupby('weighting').std() # standard deviation of mean scores across clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.boxplot(x='score', y ='weighting', data = cluster_df, hue ='weighting')\n",
    "g.legend([],[], frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
